{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Identify the direction the scooter is going in the following video of traffic in Pune.\n",
    "The video is shot by the person riding the scooter. You need to identify if the scooter is driving\n",
    "straight, going towards the left of going towards the right. Generate a video with the frames\n",
    "marked as straight, left or right to signify the direction of travel\n",
    "\n",
    "https://youtu.be/L8ftrwWT16g\n",
    "\n",
    "Author: Robin Kumar\n",
    "        robinkumar3050@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to download. I have trained my model and have kept in github link below\n",
    "# https://github.com/Robot-Robin/Computer-Vision/\n",
    "\n",
    "#make a folder in current directory as named MODEL_NAME and download below files.\n",
    "#checkpoint\n",
    "#frozen_inference_graph.pb\n",
    "#model.ckpt.data-00000-of-00001\n",
    "#model.ckpt.index\n",
    "#model.ckpt.meta\n",
    "#pipeline.config\n",
    "Model_directory = 'Direction_inf_graph'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "Frozen_ckpt = Model_directory + '/frozen_inference_graph.pb'\n",
    "Pred_Class=[\"Left\",\"Straight\",\"Right\"]\n",
    "# Number of classes i.e. left, straight, right\n",
    "Num_class = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD frozen graph to memory\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph = tf.GraphDef()\n",
    "    with tf.gfile.GFile(Frozen_ckpt, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph, name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_frame(image):\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "      # Each score represent how level of confidence for each of the objects.\n",
    "      # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "      # Actual detection.\n",
    "            (scores, classes) = sess.run([scores, classes], feed_dict={image_tensor: image_np_expanded})\n",
    "      # Predict class from score\n",
    "    index= classes[0][np.argmax(scores)]\n",
    "    value= Pred_Class[int(index)-1]\n",
    "      # value is Predicted Class string\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frame handled= 100\n",
      "Total frame handled= 200\n",
      "Total frame handled= 300\n",
      "Total frame handled= 400\n",
      "Total frame handled= 500\n",
      "Total frame handled= 600\n",
      "Total frame handled= 700\n",
      "Total frame handled= 800\n",
      "Total frame handled= 900\n",
      "Total frame handled= 1000\n",
      "Total frame handled= 1100\n",
      "Total frame handled= 1200\n",
      "Total frame handled= 1300\n",
      "Total frame handled= 1400\n",
      "Total frame handled= 1500\n",
      "Total frame handled= 1600\n",
      "Total frame handled= 1700\n",
      "Total frame handled= 1800\n",
      "Total frame handled= 1900\n",
      "Total frame handled= 2000\n",
      "Total frame handled= 2100\n",
      "Total frame handled= 2200\n",
      "Total frame handled= 2300\n",
      "Total frame handled= 2400\n",
      "Total frame handled= 2500\n",
      "Total frame handled= 2600\n",
      "Total frame handled= 2700\n",
      "Total frame handled= 2800\n",
      "Total frame handled= 2900\n",
      "Total frame handled= 3000\n",
      "Total frame handled= 3100\n",
      "Total frame handled= 3200\n",
      "Total frame handled= 3300\n",
      "Total frame handled= 3400\n",
      "Total frame handled= 3500\n",
      "Total frame handled= 3600\n",
      "Total frame handled= 3700\n",
      "Total frame handled= 3800\n",
      "Total frame handled= 3900\n",
      "Total frame handled= 4000\n",
      "Total frame handled= 4100\n",
      "Total frame handled= 4200\n",
      "Total frame handled= 4300\n",
      "Total frame handled= 4400\n",
      "Total frame handled= 4500\n",
      "Total frame handled= 4600\n",
      "Total frame handled= 4700\n",
      "Total frame handled= 4800\n",
      "Total frame handled= 4900\n",
      "Total frame handled= 5000\n",
      "Total frame handled= 5100\n",
      "Total frame handled= 5200\n",
      "Total frame handled= 5300\n",
      "Total frame handled= 5400\n",
      "Total frame handled= 5500\n",
      "Total frame handled= 5600\n",
      "Total frame handled= 5700\n",
      "Total frame handled= 5800\n",
      "Total frame handled= 5900\n",
      "Total frame handled= 6000\n",
      "Total frame handled= 6100\n",
      "Total frame handled= 6200\n",
      "Total frame handled= 6300\n",
      "Total frame handled= 6400\n",
      "Total frame handled= 6500\n",
      "Total frame handled= 6600\n",
      "Total frame handled= 6700\n",
      "Total frame handled= 6800\n",
      "Total frame handled= 6900\n",
      "Total frame handled= 7000\n",
      "Total frame handled= 7100\n",
      "Total frame handled= 7200\n",
      "Total frame handled= 7300\n",
      "Total frame handled= 7400\n",
      "Total frame handled= 7500\n",
      "Total frame handled= 7600\n",
      "Total frame handled= 7700\n",
      "Total frame handled= 7800\n",
      "Total frame handled= 7900\n",
      "Total frame handled= 8000\n"
     ]
    }
   ],
   "source": [
    "# Read video \n",
    "count=0\n",
    "\n",
    "# Downloaded form https://youtu.be/L8ftrwWT16g\n",
    "file_name=\"./Scooter.mp4\"\n",
    "# Output file name\n",
    "out_file=\"out_scooter_direction_detection.mpg\"\n",
    "\n",
    "# Read Video frames\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "cap.open(file_name)\n",
    "\n",
    "# Check valid input file\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video file\")\n",
    "    \n",
    "frame_width = int(cap.get(3)) # Capture input frame height\n",
    "frame_height = int(cap.get(4)) # Capture input frame height\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # Capture input fps\n",
    "#fourcc= cv2.VideoWriter_fourcc(*'MJPG') //codec not working\n",
    "out_vdo = cv2.VideoWriter(out_file,-1, fps, (frame_width,frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()   \n",
    "    try:\n",
    "        height,weidth= frame.shape[:2]\n",
    "    except AttributeError:\n",
    "        print(\"frame ends\")\n",
    "        break\n",
    "        \n",
    "    font_index= (200,200)\n",
    "    # Get prediction of direction\n",
    "    direction=run_inference_for_frame(frame)\n",
    "    # Put diection of scooter on frame\n",
    "    cv2.putText(frame,direction,font_index,cv2.FONT_HERSHEY_PLAIN,4,(0,0,255),3,cv2.LINE_AA)\n",
    "    # write frame to o/p file\n",
    "    out_vdo.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # Counter for testing purpose i.e. total no. of frame calculated\n",
    "    count+=1\n",
    "    if count%100 == 0:\n",
    "        print(\"Total frame handled=\",count)\n",
    "        \n",
    "print(\"Video conversion completed...\\n\",\"OutPut File= \", out_file)        \n",
    "cap.release()\n",
    "out_vdo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
